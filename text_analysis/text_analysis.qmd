---
title: "Excersice 4 - Twitter data"
author: "Tomer Zipori & Hadas Wardi"
execute: 
  warning: false
  message: false
format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 2
    toc-location: right
    embed-resources: true
editor: visual
---

# Setup

```{r}
#| output: false
library(tidyverse)
library(quanteda)
library(topicmodels)
library(quanteda.textmodels)
library(spacyr)
library(corpustools)
library(glue)
```

# Loading data

```{r}
#| output: false
twitts <- read_csv("2016-10-16 02-AM.NY.mid.csv", show_col_types = F) |>
  rename(doc_id = '...1') # renaming ID column

```

# Pre-processing

## Function

```{r}
pre_process_text <- function(txt) {
  out <- txt
  
  out <- out |>
  str_remove_all(pattern = "RT") |> # remove 'RT' prefixes specifying that this is a retweet
  str_remove_all(pattern = "http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+") |> # regex supposed to capture all urls
  str_remove_all(pattern = "@\\w+ *") |> # removing @ tags
  str_remove_all(pattern = "[[:punct:]]") |> # removing punctuation
  str_replace_all(pattern = "<.*>", replacement = " ") |> # replace unicoded emojis with spaces
  str_remove_all(pattern = "[^[:alnum:] ]") |> # now it is possible to remove everything that is not a letter or digit
  str_trim() |>
  str_squish() |>
  str_to_lower()
  
  return(out)
}
```

## preprocessing twitts column

```{r}
corp <- twitts |>
  mutate(text = pre_process_text(text))
```

## Creating corpus object

```{r}
corp <- corpus(corp, text_field = "text")
```

# Tokenizing & DTM

```{r}
dtm <- corp |>
  tokens() |>
  dfm()
```

## DTM Weighting

### Binary (Boolean) weighting

```{r}
dtm |> dfm_weight(scheme = "boolean")
```

### Proportional weighting

```{r}
dtm |> dfm_weight(scheme = "prop")
```

### tf-idf weighting

```{r}
dtm |> dfm_tfidf()
```

Note the difference between $tf-idf$ and proportional weighting...

# Topic modeling

First, converting to `topicmodels` object.

```{r}
dtm_partial <- dtm |>
  dfm_trim() |>
  convert(to = "topicmodels")
```

Now, topic modeling.

```{r}
lda_model <- topicmodels::LDA(dtm_partial, method = "Gibbs", k = 10) 
```

Inspecting some terms and their categorization.

```{r}
topicmodels::terms(lda_model, 10)
```

Too many stop words (and numbers). Filtering them out and fitting the LDA model again. We also filtered out rare tokens (less then 10 occurrences).
```{r}
dtm_partial_no_stopwords <- corp |>
          tokens(remove_numbers = T) |>
          dfm() |>
          dfm_remove(stopwords("en")) |>
          dfm_trim(min_termfreq = 10, termfreq_type = "count")

dtm_no_stopwords_lda <- dtm_partial_no_stopwords |>
  convert(to = "topicmodels")
```


Again, topic modeling.
```{r}
topic_model_trimed <- topicmodels::LDA(dtm_no_stopwords_lda, method = "Gibbs", k = 5)
```


Inspecting some terms and their categorization.
```{r}
topicmodels::terms(topic_model_trimed, 10)
```


Results are probably affected by the large number of 'non-real' words like: misspelled words, slang etc...

# Differential Language Analysis

## Which tweets get larger exposure?

Creating vaiable that indicates if a tweet has been retweeted or not
```{r}
docvars(dtm_partial_no_stopwords, "retweeted") <- docvars(dtm_partial_no_stopwords, "retweetCount") > 0

table(docvars(dtm_partial_no_stopwords, "retweeted"))
```
```{r}
#| echo: false
base_rate <- glue("${table(docvars(dtm_partial_no_stopwords, 'retweeted'))['TRUE']/(table(docvars(dtm_partial_no_stopwords, 'retweeted'))['FALSE']+table(docvars(dtm_partial_no_stopwords, 'retweeted'))['TRUE'])}$")
```

Base rate of `r base_rate`.

Train-test splitting.
```{r}
train_dtm <- dfm_sample(dtm_partial_no_stopwords, size = 800)
test_dtm <- dtm_partial_no_stopwords[setdiff(docnames(dtm_partial_no_stopwords), docnames(train_dtm)),]
```

## Naive-bayes classifier
```{r}
nb_model <- textmodel_nb(train_dtm, y = docvars(train_dtm, "retweeted"))
```

### Test performance
```{r}
pred_nb <- predict(nb_model, newdata = test_dtm)

(conmat <- table(pred_nb, docvars(test_dtm, "retweeted")))
```

Confusion matrix.
```{r}
caret::confusionMatrix(conmat, mode = "everything", positive = "TRUE")
```

