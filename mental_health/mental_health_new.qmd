---
title: "Mental Health"
author: Tomer & Hadas
date: last-modified
title-block-banner: "#525266"
execute: 
  warning: false
  message: false
  cache: true
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 3
editor: visual
---

# Setup

```{r}
#install.packages("text")
#install.packages("recipes")
#install.packages("parnsip")
#install.packages("tune")
#install.packages("tm")
#install.packages("tau")
#install.packages("starspace")
#library(parsnip)
library(tau)
library(tune)
library(tidyverse)
library(text)
library(caret)
library(tm)
library(janeaustenr)
library(quanteda)
library(quanteda.textmodels)
library(textplot)
library(spacyr)
library(glue)
library(wordcloud)
library(textdata)
library(tidytext)
```

## `text` package initialization

```{r}
#text::textrpp_initialize()
```

# Loading text

```{r}
data <- read_csv("mental_health.csv", show_col_types = F)
```

## Sampling 2 diffrent data bases to compare between

```{r}
set.seed(14)

class1 <- dplyr::slice_sample(data[data$label == 0,], n = 500, replace = F)

class2 <- dplyr::slice_sample(data[data$label == 1,], n = 500, replace = F)

data_sampled <- rbind(class1, class2)
```

# sentiment analysis

## word clout and descriptive analysis

for each data set, combine the words with NCR dictionary and understand the sentiment of each word and compare the probability.

```{r}
unique_words_1<- class1 %>%
    select(text) %>%
    unnest_tokens("word", text)

unique_words_2<- class2 %>%
    select(text) %>%
    unnest_tokens("word", text)


words_cummon1 <- unique_words_1 %>% table() %>% as.data.frame() %>% filter(Freq >10)
words_cummon2 <- unique_words_2 %>% table() %>% as.data.frame() %>% filter(Freq >10)


wordcloud(words_cummon1$word,words_cummon1$Freq)
wordcloud(words_cummon2$word,words_cummon2$Freq)

combined1 <- as.data.frame(unique_words_1) %>%
  inner_join(get_sentiments('bing')) %>%
  count(., sentiment)


combined2 <- as.data.frame(unique_words_2) %>%
  inner_join(get_sentiments('bing')) %>%
  count(., sentiment)

combined <- rbind(transform(combined1, dataset = "class1"),
                  transform(combined2, dataset = "class2"))

ggplot(combined, aes(x = sentiment, y = n, fill = sentiment)) +
  geom_bar(stat = "identity") +
  labs(x = "Sentiment", y = "Count") +
  ggtitle("Sentiment Counts by Dataset") +
  facet_wrap(~ dataset, ncol = 1) +
  scale_fill_manual(values = c("positive" = "pink", "negative" = "black"))
          

```

we can see in the second class much more negative oriented words

## DDR

```{r}
# DDR
dict <- get_sentiments("bing")

glove <- data.table::fread('glove.840B.300d.txt') %>% 
  as_tibble()

#embed dict

dict_vec <- dict |>
  inner_join(glove, by = join_by("word" == "V1")) |>
  group_by(sentiment) |>
  summarise(across(V2:V301, mean))


# embed input text --

txt <- tibble(data_sampled)

#create tokens
input_text_tok <- txt |> 
  group_by(id) |> 
  tidytext::unnest_ngrams(word, txt, n = 1) 

glove <- readRDS("glove.rds")
input_text_tok <- readRDS("input_text_tok_clean.rds")

#embed text
input_text_vec <- input_text_tok %>% 
  left_join(glove, by = c("word" = "V1")) |> 
  select(-word) |> 
  group_by(id) |> 
  summarise(across(everything(), mean, na.rm=T))

```

```{r}
#calculate cosine similarity with dict
word2vec::word2vec_similarity(as.matrix(input_text_vec), 
                              as.matrix(dict_vec), 
                              type = "cosine")

```

```{r}
#devtools::install_github("tomzhang255/CCR")


```

```{r}
text_emb <- textEmbed(data_sampled, model = #"sentence-transformers/all-MiniLM-L6-v2", layers = 6)

```

```{r}

#| evel:false
text_emb <- readRDS("text_embedded.rds")
```

## CCR

```{r}
questionnaire_JW <- c("I feel that people get what they are entitled to have",
                   "I feel that a personâ€™s efforts are noticed and rewarded",
                   "I feel that people earn the rewards and punishments they get",
                   "I feel that people who meet with misfortune have brought it on themselves",
                   "I basically feel that the world is a fair place")

questionnaire_vec <- text::textEmbed(questionnaire_JW, 
                                     model = 'sentence-transformers/all-MiniLM-L6-v2', 
                                     layers = 6)

questionnaire_vec_avg <- questionnaire_vec$texts$texts %>% 
  summarise(across(everything(), mean))

text::textSimilarity(text_emb$texts$texts, questionnaire_vec_avg)


```
